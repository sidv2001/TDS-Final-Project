{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import kagglehub\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from typing import Dict, List, Set, Tuple\n",
    "from tqdm.notebook import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_dir = kagglehub.dataset_download(\"andrewmvd/spotify-playlists\")\n",
    "playlist_file = None\n",
    "for root, dirs, files in os.walk(playlist_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            playlist_file = os.path.join(root, file)\n",
    "            break\n",
    "playlists_df = pd.read_csv(\n",
    "    playlist_file,\n",
    "    names=['user_id', 'artistname', 'trackname', 'playlistname'],\n",
    "    skiprows=1,\n",
    "    quoting=csv.QUOTE_ALL,\n",
    "    escapechar='\\\\',\n",
    "    on_bad_lines='skip'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_tracks_df = pd.read_csv(\"hf://datasets/maharshipandya/spotify-tracks-dataset/dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_tracks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: sort the spotify_tracks_df based on popularity (and print that out)\n",
    "\n",
    "# Sort the DataFrame by popularity in descending order\n",
    "spotify_tracks_df_sorted = spotify_tracks_df.sort_values(by='popularity', ascending=False)\n",
    "\n",
    "# Print the sorted DataFrame\n",
    "spotify_tracks_df_sorted.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_nulls = playlists_df.isnull().any(axis=1).sum()\n",
    "rows_with_nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Percentage of rows with missing values: {(rows_with_nulls/len(playlists_df)*100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spotify_tracks_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_nulls = spotify_tracks_df.isnull().any(axis=1).sum()\n",
    "rows_with_nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Percentage of rows with missing values: {(rows_with_nulls/len(spotify_tracks_df)*100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists_df_clean = playlists_df.dropna()\n",
    "print(f\"Original rows: {len(playlists_df)}\")\n",
    "print(f\"Rows after dropping nulls: {len(playlists_df_clean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_tracks_df_clean = spotify_tracks_df.dropna()\n",
    "print(f\"Original rows: {len(spotify_tracks_df)}\")\n",
    "print(f\"Rows after dropping nulls: {len(spotify_tracks_df_clean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists_df_clean = playlists_df.dropna().copy()\n",
    "\n",
    "playlists_df_clean.loc[:, 'track_clean'] = playlists_df_clean['trackname'].str.lower().str.strip()\n",
    "playlists_df_clean.loc[:, 'artist_clean'] = playlists_df_clean['artistname'].str.lower().str.strip()\n",
    "\n",
    "spotify_tracks_df.loc[:, 'track_clean'] = spotify_tracks_df['track_name'].str.lower().str.strip()\n",
    "spotify_tracks_df.loc[:, 'artists_clean'] = spotify_tracks_df['artists'].str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates in playlists_df_clean\n",
    "print(f\"Duplicate rows in playlists_df_clean: {playlists_df_clean.duplicated().sum()}\")\n",
    "if playlists_df_clean.duplicated().sum() > 0:\n",
    "    print(playlists_df_clean[playlists_df_clean.duplicated(keep=False)])\n",
    "\n",
    "# Check for duplicates in spotify_tracks_df_clean\n",
    "print(f\"Duplicate rows in spotify_tracks_df_clean: {spotify_tracks_df_clean.duplicated().sum()}\")\n",
    "if spotify_tracks_df_clean.duplicated().sum() > 0:\n",
    "    print(spotify_tracks_df_clean[spotify_tracks_df_clean.duplicated(keep=False)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = playlists_df_clean.merge(\n",
    "    spotify_tracks_df,\n",
    "    left_on=['track_clean', 'artist_clean'],\n",
    "    right_on=['track_clean', 'artists_clean'],\n",
    "    how='inner'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Original playlist rows: {len(playlists_df_clean)}\")\n",
    "print(f\"Original spotify tracks rows: {len(spotify_tracks_df)}\")\n",
    "print(f\"Matched rows: {len(merged_df)}\")\n",
    "print(f\"Percentage of playlist songs matched: {(len(merged_df)/len(playlists_df_clean)*100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFirst few matches:\")\n",
    "print(merged_df[['trackname', 'track_name', 'artistname', 'artists']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique songs in matched data:\")\n",
    "print(f\"Unique song-artist pairs in matched data: {merged_df[['track_clean', 'artist_clean']].nunique().iloc[0]}\")\n",
    "print(f\"Unique playlists with at least one matched song: {merged_df['playlistname'].nunique()}\")\n",
    "\n",
    "playlist_matches = merged_df.groupby('playlistname').size()\n",
    "print(\"\\nMatched songs per playlist statistics:\")\n",
    "print(playlist_matches.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged_df) , len(merged_df.groupby(['playlistname', \"user_id\"]).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged_df) , len(merged_df.groupby(['playlistname', \"user_id\"]).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: plotted distribution of the number of songs in each group (grouped by playlistname and user_id)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Group by playlistname and user_id and count the number of songs\n",
    "song_counts = merged_df.groupby(['playlistname', 'user_id']).size()\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(song_counts, kde=True)\n",
    "plt.title('Distribution of Number of Songs per Playlist and User')\n",
    "plt.xlabel('Number of Songs')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: number of groups with more than 100 songs (use the songcount variable)\n",
    "\n",
    "# Calculate the number of groups with more than 100 songs\n",
    "num_groups_over_100 = sum(1 for count in song_counts if count > 1000)\n",
    "\n",
    "print(f\"Number of groups with more than 100 songs: {num_groups_over_100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.iloc[:10, 11:27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: sort the spotify tracks dataset based on popularity\n",
    "\n",
    "# Sort the merged DataFrame by popularity in descending order\n",
    "merged_df_sorted = merged_df.sort_values(by='popularity', ascending=False)\n",
    "\n",
    "# Display the sorted DataFrame (or work with it as needed)\n",
    "print(merged_df_sorted.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Drop playlists with fewer than 10 songs\n",
    "# -----------------------------------------------\n",
    "# Compute the counts of songs per playlist\n",
    "playlist_counts = merged_df.groupby(['playlistname', 'user_id']).size().reset_index(name='counts')\n",
    "\n",
    "# Filter playlists with at least 10 songs\n",
    "valid_playlists = playlist_counts[playlist_counts['counts'] >= 10][['playlistname', 'user_id']]\n",
    "\n",
    "# Merge back to the original DataFrame to keep only valid playlists\n",
    "merged_df_valid = merged_df.merge(valid_playlists, on=['playlistname', 'user_id'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged_df_valid), len(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists = merged_df_valid[['playlistname', 'user_id']].drop_duplicates()\n",
    "\n",
    "# Shuffle the playlists\n",
    "playlists = playlists.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Compute split indices\n",
    "total_playlists = len(playlists)\n",
    "train_end = int(0.8 * total_playlists)\n",
    "val_end = int(0.9 * total_playlists)\n",
    "\n",
    "# Assign playlists to train, validation, and test sets\n",
    "playlists['set'] = ['train'] * train_end + ['val'] * (val_end - train_end) + ['test'] * (total_playlists - val_end)\n",
    "\n",
    "# Merge the set assignments back to the main DataFrame\n",
    "merged_df_valid = merged_df_valid.merge(playlists, on=['playlistname', 'user_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_XY(group):\n",
    "    # Shuffle the songs within the playlist\n",
    "    group = group.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    total_songs = len(group)\n",
    "    split_point = int(0.8 * total_songs)\n",
    "    group['XY'] = ['X'] * split_point + ['Y'] * (total_songs - split_point)\n",
    "    return group\n",
    "\n",
    "# Apply the function to each set\n",
    "merged_df_valid = merged_df_valid.groupby(['playlistname', 'user_id', 'set'], group_keys=False).apply(assign_XY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to keep as per your specification\n",
    "columns_to_keep = [\n",
    "    'playlistname',   # 1. The playlist it is from\n",
    "    'user_id',        # 2. The user who created the playlist\n",
    "    'track_clean',    # 3. The song name\n",
    "    'artist_clean',   # 4. The artist name\n",
    "    'album_name'      # 5. The album name\n",
    "]\n",
    "\n",
    "# Add the features from columns 11 to 27 (0-indexed)\n",
    "# Assuming merged_df has the original columns from 0 to N\n",
    "# Get the column names for columns 11 to 27\n",
    "feature_columns = merged_df.columns[11:27].tolist()\n",
    "columns_to_keep += feature_columns\n",
    "\n",
    "# Add the 'XY' column for labels\n",
    "columns_to_keep += ['XY']\n",
    "\n",
    "# Now, filter the DataFrame to keep only these columns\n",
    "merged_df_valid = merged_df_valid[columns_to_keep + ['set']]  # Include 'set' to separate datasets\n",
    "# Create a unique song ID using 'track_clean' and 'artist_clean'\n",
    "merged_df_valid['song_id'] = merged_df_valid['track_clean'] + ' - ' + merged_df_valid['artist_clean']\n",
    "\n",
    "# Create a unique playlist ID using 'playlistname' and 'user_id'\n",
    "merged_df_valid['playlist_id'] = merged_df_valid['playlistname'] + ' - ' + merged_df_valid['user_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_valid.iloc[100:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_valid.to_csv('data/full_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = merged_df_valid[merged_df_valid['set'] == 'train'].drop(columns=['set'])\n",
    "val_df = merged_df_valid[merged_df_valid['set'] == 'val'].drop(columns=['set'])\n",
    "test_df = merged_df_valid[merged_df_valid['set'] == 'test'].drop(columns=['set'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('data/train.csv', index=False)\n",
    "val_df.to_csv('data/val.csv', index=False)\n",
    "test_df.to_csv('data/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
